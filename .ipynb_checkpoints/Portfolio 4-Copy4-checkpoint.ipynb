{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "8cdf8add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is my COMP2200 Data Science Portfolio 4 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747c315c",
   "metadata": {},
   "source": [
    "## Data Science Portfolio Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4709ce6",
   "metadata": {},
   "source": [
    "The goal of the second analysis task is to train linear regression models to predict users' ratings towards items. This involves a standard Data Science workflow: exploring data, building models, making predictions, and evaluating results. In this task, we will explore the impacts of feature selections and different sizes of training/testing data on the model performance. We will use another cleaned combined e-commerce sub-dataset that **is different from** the one in “Analysis of an E-commerce Dataset” task 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d95a739",
   "metadata": {},
   "source": [
    "### Import Cleaned E-commerce Dataset\n",
    "The csv file named 'cleaned_ecommerce_dataset.csv' is provided. You may need to use the Pandas method, i.e., `read_csv`, for reading it. After that, please print out its total length."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebff4cf",
   "metadata": {},
   "source": [
    "### Explore the Dataset\n",
    "\n",
    "* Use the methods, i.e., `head()` and `info()`, to have a rough picture about the data, e.g., how many columns, and the data types of each column.\n",
    "* As our goal is to predict ratings given other columns, please get the correlations between helpfulness/gender/category/review and rating by using the `corr()` method.\n",
    "* To get the correlations between different features, you may need to first convert the categorical features (i.e., gender, category and review) into numerial values. For doing this, you may need to import `OrdinalEncoder` from `sklearn.preprocessing` (refer to the useful exmaples [here](https://pbpython.com/categorical-encoding.html))\n",
    "* Please provide ___necessary explanations/analysis___ on the correlations, and figure out which are the ___most___ and ___least___ corrleated features regarding rating. Try to ___discuss___ how the correlation will affect the final prediction results, if we use these features to train a regression model for rating prediction. In what follows, we will conduct experiments to verify your hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "e8fa69de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library   \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Import ignore warnings \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "ffad8748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load World Development Indicators data into this notebook\n",
    "\n",
    "df = pd.read_csv(\"WorldDevelopmentIndicators.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efe61dc",
   "metadata": {},
   "source": [
    "## 1. Exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "0bddb3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the length of the dataset before cleaning\n",
    "\n",
    "print('Length of the dataset before cleaning: ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "c5bdf7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the dataset using the method head()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "ed96997c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Displaying the dataframe before cleaning\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "01097c70",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Displaying a summary of the dataframe\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "e13ec6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the number of countries in the dataset\n",
    "\n",
    "print('Number of countries:', len(df['Country'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "17b44fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the number of years the data has been collected across\n",
    "\n",
    "print('Number of years:', len(df['Year'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "9005301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the dimensions of the dataset before cleaning\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "55eda7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying descriptive statistics for Life Expectancy\n",
    "\n",
    "df['LifeExpectancy'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "f6e62f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the country with the lowest life expectancy across all years\n",
    "\n",
    "LifeExpectancyMin = df['LifeExpectancy'].min()\n",
    "print(df.loc[df['LifeExpectancy'] == LifeExpectancyMin, ['Country', 'Year', 'LifeExpectancy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "05736d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the country with the highest life expectancy across all years\n",
    "\n",
    "LifeExpectancyMax = df['LifeExpectancy'].max()\n",
    "print(df.loc[df['LifeExpectancy'] == LifeExpectancyMax, ['Country', 'Year', 'LifeExpectancy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "c025fce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the country with the lowest life expectancy in 2020\n",
    "\n",
    "Data2020 = df.loc[df['Year'] == 2020]\n",
    "LifeExpectancyMin2020 = Data2020['LifeExpectancy'].min()\n",
    "print(df.loc[df['LifeExpectancy'] == LifeExpectancyMin2020, ['Country', 'Year', 'LifeExpectancy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "f000d398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the country with the highest life expectancy in 2020\n",
    "\n",
    "Data2020 = df.loc[df['Year'] == 2020]\n",
    "LifeExpectancyMax2020 = Data2020['LifeExpectancy'].max()\n",
    "print(df.loc[df['LifeExpectancy'] == LifeExpectancyMax2020, ['Country', 'Year', 'LifeExpectancy']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64750e17",
   "metadata": {},
   "source": [
    "## 2. Cleaning the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "04f33549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the number of null values in each column\n",
    "\n",
    "print('Number of null values in Country:', df['Country'].isna().sum())\n",
    "print('Number of null values in Year:', df['Year'].isna().sum())\n",
    "print('Number of null values in Agriculture:', df['Agriculture'].isna().sum())\n",
    "print('Number of null values in Exports:', df['Exports'].isna().sum())\n",
    "print('Number of null values in FertilityRate:', df['FertilityRate'].isna().sum())\n",
    "print('Number of null values in GDP:', df['GDP'].isna().sum())\n",
    "print('Number of null values in Immunisation:', df['Immunisation'].isna().sum())\n",
    "print('Number of null values in Imports:', df['Imports'].isna().sum())\n",
    "print('Number of null values in Industry:', df['Industry'].isna().sum())\n",
    "print('Number of null values in Inflation:', df['Inflation'].isna().sum())\n",
    "print('Number of null values in MerchandiseTrade:', df['MerchandiseTrade'].isna().sum())\n",
    "print('Number of null values in MilitaryExpenditure:', df['MilitaryExpenditure'].isna().sum())\n",
    "print('Number of null values in MortalityRateU5:', df['MortalityRateU5'].isna().sum())\n",
    "print('Number of null values in NetMigration:', df['NetMigration'].isna().sum())\n",
    "print('Number of null values in DevelopmentAssistanceAndAid:', df['DevelopmentAssistanceAndAid'].isna().sum())\n",
    "print('Number of null values in PopulationDensity:', df['PopulationDensity'].isna().sum())\n",
    "print('Number of null values in PopulationGrowth:', df['PopulationGrowth'].isna().sum())\n",
    "print('Number of null values in PrimarySchoolEnrollment:', df['PrimarySchoolEnrollment'].isna().sum())\n",
    "print('Number of null values in UrbanPopulationGrowth:', df['UrbanPopulationGrowth'].isna().sum())\n",
    "print('Number of null values in LifeExpectancy:', df['LifeExpectancy'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "6113e85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing records where values are missing\n",
    "\n",
    "clean_df = df.dropna(subset=['Agriculture', \n",
    "                             'Exports', \n",
    "                             'FertilityRate', \n",
    "                             'GDP', \n",
    "                             'Immunisation', \n",
    "                             'Imports', \n",
    "                             'Industry', \n",
    "                             'Inflation', \n",
    "                             'MerchandiseTrade', \n",
    "                             'MilitaryExpenditure', \n",
    "                             'MortalityRateU5', \n",
    "                             'NetMigration', \n",
    "                             'DevelopmentAssistanceAndAid', \n",
    "                             'PopulationDensity', \n",
    "                             'PopulationGrowth', \n",
    "                             'PrimarySchoolEnrollment', \n",
    "                             'UrbanPopulationGrowth', \n",
    "                             'LifeExpectancy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "56c7688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the length of the dataset after cleaning\n",
    "\n",
    "print('Length of the dataset after cleaning: ', len(clean_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "900207d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying a summary of the cleaned dataset\n",
    "\n",
    "clean_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "f0ed3bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the number of null values in each column after cleaning\n",
    "\n",
    "print('Number of null values in Country:', clean_df['Country'].isna().sum())\n",
    "print('Number of null values in Year:', clean_df['Year'].isna().sum())\n",
    "print('Number of null values in Agriculture:', clean_df['Agriculture'].isna().sum())\n",
    "print('Number of null values in Exports:', clean_df['Exports'].isna().sum())\n",
    "print('Number of null values in FertilityRate:', clean_df['FertilityRate'].isna().sum())\n",
    "print('Number of null values in GDP:', clean_df['GDP'].isna().sum())\n",
    "print('Number of null values in Immunisation:', clean_df['Immunisation'].isna().sum())\n",
    "print('Number of null values in Imports:', clean_df['Imports'].isna().sum())\n",
    "print('Number of null values in Industry:', clean_df['Industry'].isna().sum())\n",
    "print('Number of null values in Inflation:', clean_df['Inflation'].isna().sum())\n",
    "print('Number of null values in MerchandiseTrade:', clean_df['MerchandiseTrade'].isna().sum())\n",
    "print('Number of null values in MilitaryExpenditure:', clean_df['MilitaryExpenditure'].isna().sum())\n",
    "print('Number of null values in MortalityRateU5:', clean_df['MortalityRateU5'].isna().sum())\n",
    "print('Number of null values in NetMigration:', clean_df['NetMigration'].isna().sum())\n",
    "print('Number of null values in DevelopmentAssistanceAndAid:', clean_df['DevelopmentAssistanceAndAid'].isna().sum())\n",
    "print('Number of null values in PopulationDensity:', clean_df['PopulationDensity'].isna().sum())\n",
    "print('Number of null values in PopulationGrowth:', clean_df['PopulationGrowth'].isna().sum())\n",
    "print('Number of null values in PrimarySchoolEnrollment:', clean_df['PrimarySchoolEnrollment'].isna().sum())\n",
    "print('Number of null values in UrbanPopulationGrowth:', clean_df['UrbanPopulationGrowth'].isna().sum())\n",
    "print('Number of null values in LifeExpectancy:', clean_df['LifeExpectancy'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "3da9278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the dataframe after cleaning\n",
    "\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "43fea2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the shape of the dataset after cleaning \n",
    "\n",
    "clean_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556c73da",
   "metadata": {},
   "source": [
    "## 3. Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "07b455c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the length of the dataset after before removing outliers\n",
    "\n",
    "print('Length of the dataset before removing outliers: ', len(clean_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "05acaa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the number of records in each 5 year timespan (and prior to 1980)\n",
    "\n",
    "print('Number of records in 1960-1979:', len(clean_df[(clean_df.Year >= 1960) & (clean_df.Year < 1980)]))\n",
    "print('Number of records in 1980-1984:', len(clean_df[(clean_df.Year >= 1980) & (clean_df.Year < 1985)]))\n",
    "print('Number of records in 1985-1989:', len(clean_df[(clean_df.Year >= 1985) & (clean_df.Year < 1990)]))\n",
    "print('Number of records in 1990-1994:', len(clean_df[(clean_df.Year >= 1990) & (clean_df.Year < 1995)]))\n",
    "print('Number of records in 1995-1999:', len(clean_df[(clean_df.Year >= 1995) & (clean_df.Year < 2000)]))\n",
    "print('Number of records in 2000-2004:', len(clean_df[(clean_df.Year >= 2000) & (clean_df.Year < 2005)]))\n",
    "print('Number of records in 2005-2009:', len(clean_df[(clean_df.Year >= 2005) & (clean_df.Year < 2010)]))\n",
    "print('Number of records in 2010-2014:', len(clean_df[(clean_df.Year >= 2010) & (clean_df.Year < 2015)]))\n",
    "print('Number of records in 2015-2019:', len(clean_df[(clean_df.Year >= 2015) & (clean_df.Year < 2020)]))\n",
    "print('Number of records in 2020-2024:', len(clean_df[(clean_df.Year >= 2020) & (clean_df.Year < 2025)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "19bc9540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying records collected prior to 1985\n",
    "\n",
    "before1985 = (clean_df['Year']) < 1985"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "2e36bd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing records collected prior to 1985\n",
    "\n",
    "clean_df_2 = clean_df.drop(clean_df.index[before1985])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "5b5682ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the length of the dataset after removing outliers\n",
    "\n",
    "print('Length of the dataset after removing outliers: ', len(clean_df_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "f75e138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the cleaned dataset as a new file\n",
    "\n",
    "clean_df_2.to_csv('WorldDevelopmentIndicatorsClean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2600a3e0",
   "metadata": {},
   "source": [
    "# 4. Exploring cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "e55e9e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"WorldDevelopmentIndicatorsClean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "20d3ee31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the length of the dataset before cleaning\n",
    "\n",
    "print('Length of the cleaned WorldDevelopmentIndicators dataset: ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "18c31586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the dataframe of the cleaned WorldDevelopmentIndicators dataset\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "25e1e7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying a summary of the dataframe\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "dfcc901a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the number of countries in the dataset\n",
    "\n",
    "print('Number of countries:', len(df['Country'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "d75c13c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the number of years the data has been collected across\n",
    "\n",
    "print('Number of years:', len(df['Year'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "fc76d34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the number of records for each country\n",
    "\n",
    "df.groupby(['Country'])['LifeExpectancy'].count().reset_index(name='Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "a1920922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the number of records for each country in ascending order\n",
    "\n",
    "(df.groupby(['Country'])['LifeExpectancy'].count().reset_index(name='Count')).sort_values(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "ad2eb127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying descriptive statistics for Life Expectancy\n",
    "\n",
    "df['LifeExpectancy'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd49df2f",
   "metadata": {},
   "source": [
    "## 5. Plotting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "d2d7d8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the average value for each Indicator each year to be graphed\n",
    "\n",
    "byIndicator = df.groupby(['Year'])['Agriculture', \n",
    "            'Exports', \n",
    "            'FertilityRate', \n",
    "            'GDP', \n",
    "            'Immunisation', \n",
    "            'Imports', \n",
    "            'Industry', \n",
    "            'Inflation', \n",
    "            'MerchandiseTrade', \n",
    "            'MilitaryExpenditure', \n",
    "            'MortalityRateU5', \n",
    "            'NetMigration', \n",
    "            'DevelopmentAssistanceAndAid', \n",
    "            'PopulationDensity', \n",
    "            'PopulationGrowth', \n",
    "            'PrimarySchoolEnrollment', \n",
    "            'UrbanPopulationGrowth', \n",
    "            'LifeExpectancy'].mean()\n",
    "byIndicator.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "13a01c4f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting the average trends of each Indicator over time\n",
    "\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "\n",
    "byIndicator.plot.line(subplots = True, figsize = (15, 30),sharex = True)\n",
    "plt.style.use('classic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "001c5fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the average Life Expectancy for each Year each year to be graphed\n",
    "\n",
    "byYear = df.groupby(['Year'])['LifeExpectancy'].mean().reset_index(name='MeanLifeExpectancy')\n",
    "byYear.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "c0711838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphing life expectancy against year\n",
    "\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "\n",
    "byYear.plot.line(x = 'Year', \n",
    "                 y = 'MeanLifeExpectancy', \n",
    "                 title = 'Line Graph of Life Expectancy against Year', \n",
    "                 color = 'indigo')\n",
    "plt.style.use('classic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "97dfd051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing sns package\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "8f9ae4fb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Graphing Life expectancy and year by country\n",
    "\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(20,30)})\n",
    "sns.scatterplot(data = df, \n",
    "                x = \"Year\", \n",
    "                y = \"LifeExpectancy\", \n",
    "                hue = \"Country\"\n",
    "               #size=\"size\", sizes=(20, 200), hue_norm=(0, 7), legend=\"full\"\n",
    "               )\n",
    "plt.style.use('classic')\n",
    "plt.title('Scatterplot of Life Expectancy by Year with Country')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f57130",
   "metadata": {},
   "source": [
    "## 6. Exploring the correlation of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "e174112f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the head of the dataset\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "0485ed50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing ordinal encoder\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "1c2edf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring ordinal encoder - datatype is integer\n",
    "\n",
    "enc = OrdinalEncoder(dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "601722e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 'Country' to numerical data - creating column 'CountryCode'\n",
    "\n",
    "df['CountryCode'] = enc.fit_transform(df[['Country']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "a9da5be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the head of the dataset\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "b2d7dcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying 'Country' with new code column 'CountryCode'\n",
    "\n",
    "df[[\"Country\", \"CountryCode\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "0bceeffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the 'Country' column which has now been replaced by 'CountryCode'\n",
    "\n",
    "df = df.drop(columns = ['Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "135ef00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making 'LifeExpectancy' a categorial variable in preparation for logistic regression\n",
    "\n",
    "df1 = df\n",
    "df1.round({\"LifeExpectancy\":2})\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "a344d075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the head of the dataset\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "1b91acf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the correlations between all indicators\n",
    "\n",
    "df[['Year',\n",
    "    'CountryCode',\n",
    "    'Agriculture', \n",
    "    'Exports', \n",
    "    'FertilityRate', \n",
    "    'GDP', \n",
    "    'Immunisation', \n",
    "    'Imports', \n",
    "    'Industry', \n",
    "    'Inflation', \n",
    "    'MerchandiseTrade', \n",
    "    'MilitaryExpenditure', \n",
    "    'MortalityRateU5', \n",
    "    'NetMigration', \n",
    "    'DevelopmentAssistanceAndAid', \n",
    "    'PopulationDensity', \n",
    "    'PopulationGrowth', \n",
    "    'PrimarySchoolEnrollment', \n",
    "    'UrbanPopulationGrowth',\n",
    "    'LifeExpectancy']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "5e8ec49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the correlation between all Indicators and Life expectancy\n",
    "\n",
    "print('correlation between Year and LifeExpectancy:', df['Year'].corr(df['LifeExpectancy']))\n",
    "print('correlation between CountryCode and LifeExpectancy:', df['CountryCode'].corr(df['LifeExpectancy']))\n",
    "print('correlation between Agriculture and LifeExpectancy:', df['Agriculture'].corr(df['LifeExpectancy']))\n",
    "print('correlation between Exports and LifeExpectancyy:', df['Exports'].corr(df['LifeExpectancy']))\n",
    "print('correlation between FertilityRate and LifeExpectancy:', df['FertilityRate'].corr(df['LifeExpectancy']))\n",
    "print('correlation between GDP and LifeExpectancy:', df['GDP'].corr(df['LifeExpectancy']))\n",
    "print('correlation between Immunisation and LifeExpectancy:', df['Immunisation'].corr(df['LifeExpectancy']))\n",
    "print('correlation between Imports and LifeExpectancy:', df['Imports'].corr(df['LifeExpectancy']))\n",
    "print('correlation between Industry and LifeExpectancy:', df['Industry'].corr(df['LifeExpectancy']))\n",
    "print('correlation between Inflation and LifeExpectancy:', df['Inflation'].corr(df['LifeExpectancy']))\n",
    "print('correlation between MerchandiseTrade and LifeExpectancy:', df['MerchandiseTrade'].corr(df['LifeExpectancy']))\n",
    "print('correlation between MortalityRateU5 and LifeExpectancy:', df['MortalityRateU5'].corr(df['LifeExpectancy']))\n",
    "print('correlation between NetMigration and LifeExpectancy:', df['NetMigration'].corr(df['LifeExpectancy']))\n",
    "print('correlation between DevelopmentAssistanceAndAid and LifeExpectancy:', df['DevelopmentAssistanceAndAid'].corr(df['LifeExpectancy']))\n",
    "print('correlation between PopulationDensity and LifeExpectancy:', df['PopulationDensity'].corr(df['LifeExpectancy']))\n",
    "print('correlation between PopulationGrowth and LifeExpectancy:', df['PopulationGrowth'].corr(df['LifeExpectancy']))\n",
    "print('correlation between PrimarySchoolEnrollment and LifeExpectancy:', df['PrimarySchoolEnrollment'].corr(df['LifeExpectancy']))\n",
    "print('correlation between UrbanPopulationGrowth and LifeExpectancy:', df['UrbanPopulationGrowth'].corr(df['LifeExpectancy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "e5abde3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using heatmap to show correlations\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(data= df.corr(), annot=True, cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "aed95786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining X and Y\n",
    "X = df.drop(['LifeExpectancy'], axis = 1)\n",
    "y = df['LifeExpectancy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "64276016",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Correlation with independent variable\n",
    "\n",
    "X.corrwith(df.LifeExpectancy).plot.bar(figsize = (15, 10), title = \"Correlation with LifeExpectancy\", fontsize = 10,grid = True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "09fc87d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Custom correlation matrix\n",
    "\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# Using df.corr() to set up the correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "# Covering the upper diagonal of the matrix\n",
    "mask = np.zeros_like(corr, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Setting up the figure\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(500, 40, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b43bde",
   "metadata": {},
   "source": [
    "## 7. Training a Logistic Regression model to predict LifeExpectancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "a696b675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the train_test_split package\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "f2c7d0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset - testing size of 20% - randomstate = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['LifeExpectancy']), df['LifeExpectancy'], test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "25bfc009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the shape of the training and testing sets\n",
    "\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "a592fb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Logistic Regression Model\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "ff905fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Logistic Regression Model to predict 'rating' bsed on other features\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf916e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the accuracy_score package\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22616a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the accuracy of the model\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy of logistic regression: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92997e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying K-folds validation\n",
    " \n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "accuracies = cross_val_score(estimator= classifier, X=X_train, y=y_train, cv=10)\n",
    "accuracies.mean()\n",
    "accuracies.std()\n",
    "print('Logistic Regression Accuracy: %0.3f (+/- %0.3f)' % (accuracies.mean(), accuracies.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9373caa7",
   "metadata": {},
   "source": [
    "## 8. Using RFE to improve Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3255821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using RFE to optimise number of features\n",
    "\n",
    "estimator = LogisticRegression()\n",
    "acc_scores = []\n",
    "for i in range(1, 10):\n",
    "    selector = RFE(estimator,n_features_to_select=i)\n",
    "    selector = selector.fit(X_train, y_train)\n",
    "    supp = selector.get_support()\n",
    "\n",
    "    predicted = selector.predict(X_test)\n",
    "    acc_score = accuracy_score(y_test, predicted)\n",
    "    acc_scores.append(acc_score)\n",
    "\n",
    "best = 1\n",
    "for item in acc_scores:\n",
    "    if item < acc_scores[best - 1]:\n",
    "        best = acc_scores.index(item) + 1\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel('# No. of features')\n",
    "plt.ylabel('Accuracy score on test set')\n",
    "plt.plot(range(1, 10), acc_scores, marker = 'o', color = 'blueviolet', markeredgewidth = 1 ,markeredgecolor = 'royalblue', markerfacecolor = 'royalblue')\n",
    "plt.plot(best, acc_scores[best-1], marker = 'o', markerfacecolor = 'blueviolet')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4e24cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing RFE package\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Selecting the 2 best features \n",
    "rfe = RFE(clf, n_features_to_select= 2)\n",
    "rfe = rfe.fit(X_train, y_train)\n",
    "\n",
    "# Summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)\n",
    "X_train.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119e3c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarising all features\n",
    "\n",
    "for i in range(X_train.shape[1]):\n",
    "    print('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988e6c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating RFE object\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "rfe = RFE(estimator=lr_model, n_features_to_select=2, step=1)\n",
    "rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82330c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating RFE\n",
    "\n",
    "y_pred = rfe.predict(X_test)\n",
    "print(\"accuracy score on test set: \", accuracy_score(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4787c99",
   "metadata": {},
   "source": [
    "## Improving by inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1616f56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset - testing size of 20% - randomstate = 42\n",
    "\n",
    "# Separating dataframe into data and target\n",
    "\n",
    "data = df[[\"MortalityRateU5\", \"Immunisation\"]]\n",
    "target = df['LifeExpectancy']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38547795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the shape of the training and testing sets\n",
    "\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed27cb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Logistic Regression Model to predict 'rating' bsed on other features\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757c795e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the accuracy of the model\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy of logistic regression: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79c08b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddd2032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd9ff73d",
   "metadata": {},
   "source": [
    "## 10. Training a KNN model to predict LifeExpectancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d22a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the KNN model package\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa5c048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating dataframe into data and target\n",
    "\n",
    "data = df.drop(columns = ['LifeExpectancy'])\n",
    "target = df['LifeExpectancy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdf7644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size = 0.2, random_state=142)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f4aa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train shape: {}\".format(X_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "print(\"X_test shape: {}\".format(X_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd36d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the KNN model - performance of model is highly dependent on k-value - a k-value of 3 has been chosen\n",
    "\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=3)\n",
    "clf_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943cae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the accuracy of the KNN model\n",
    "\n",
    "y_pred = clf_knn.predict(X_test)\n",
    "print(\"Accuracy of KNN: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d02d04a",
   "metadata": {},
   "source": [
    "## 11. Optimising KNN by tuning hyperparameter k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c09837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15996d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't need to train a model or test accuracy because cross validation does it for us\n",
    "\n",
    "cv_scores = []\n",
    "cv_scores_std = []\n",
    "k_range = range(1, 150, 5) # change last number to 1 to iterate every value\n",
    "for i in k_range:\n",
    "    clf = KNeighborsClassifier(n_neighbors = i)\n",
    "    scores = cross_val_score(clf, data, target, scoring='accuracy', cv=KFold(n_splits=10, shuffle=True))\n",
    "    cv_scores.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())\n",
    "\n",
    "# Plot the relationship\n",
    "plt.errorbar(k_range, cv_scores, yerr=cv_scores_std, marker='x', label='Accuracy')\n",
    "plt.ylim([0.1, 1.1])\n",
    "plt.xlabel('$K$')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlim(0, 150)\n",
    "plt.ylim(0, 0.2)\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "# vertical bar shows standard deviation\n",
    "# we want the standard deviation to be as short as possible\n",
    "# accuracy of the model can vary greatly - stableness or robustness\n",
    "# need to find optimal hyper-parameter manually by observation - or use gridsearch cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a34a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing GridSearch\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7091b0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using GridSearch to find the optimal value of the hyper-parameter K - Optimal value will be selected within 1 - 100\n",
    "\n",
    "parameters = {'n_neighbors': range(1, 150)}\n",
    "knn = KNeighborsClassifier()\n",
    "gridSearch = GridSearchCV(knn, parameters, scoring='accuracy', cv=KFold(n_splits=10, shuffle=True))\n",
    "gridSearch.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c52211a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the optimal K value\n",
    "\n",
    "gridSearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4603c461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't need to train a model or test accuracy because cross validation does it for us\n",
    "\n",
    "cv_scores = []\n",
    "cv_scores_std = []\n",
    "k_range = range(130, 150, 1) # change last number to 1 to iterate every value\n",
    "for i in k_range:\n",
    "    clf = KNeighborsClassifier(n_neighbors = i)\n",
    "    scores = cross_val_score(clf, data, target, scoring='accuracy', cv=KFold(n_splits=10, shuffle=True))\n",
    "    cv_scores.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())\n",
    "\n",
    "# Plot the relationship\n",
    "plt.errorbar(k_range, cv_scores, yerr=cv_scores_std, marker='x', label='Accuracy')\n",
    "plt.ylim([0.1, 1.1])\n",
    "plt.xlabel('$K$')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlim(130, 150)\n",
    "plt.ylim(0, 0.2)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec2af71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the best accuracy score of the model\n",
    "\n",
    "gridSearch.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcec2fd",
   "metadata": {},
   "source": [
    "## 8. Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e86ad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing GaussianNB and make_classification packages\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb43fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and training a Gaussian Naive Bayes classifier model\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to predict testing data\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print('Testing accuracy is: %.4f\\n' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea04c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_nb = {\n",
    "    'var_smoothing': np.logspace(0,-9, num=100)\n",
    "}\n",
    "\n",
    "nbModel_grid = GridSearchCV(estimator=GaussianNB(), param_grid=param_grid_nb, verbose=1, cv=10, n_jobs=-1)\n",
    "nbModel_grid.fit(X_train, y_train)\n",
    "print(nbModel_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aa1cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d19065b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd66aa66",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Use 10-fold cross validation to show a more robust prediction accuracy\n",
    "clf = GaussianNB()\n",
    "scores = cross_val_score(clf, X, y, scoring='accuracy', cv=100)\n",
    "print('Gaussian Naive Bayes accuracy range: [%.4f, %.4f]; mean: %.4f; std: %.4f\\n' % (scores.min(), scores.max(), scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2144c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
