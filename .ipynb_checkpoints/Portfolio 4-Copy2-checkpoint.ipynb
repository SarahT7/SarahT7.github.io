{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1348,
   "id": "a5119aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is my COMP2200 Data Science Portfolio 4 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30218265",
   "metadata": {},
   "source": [
    "## Data Science Portfolio Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4709ce6",
   "metadata": {},
   "source": [
    "The goal of the second analysis task is to train linear regression models to predict users' ratings towards items. This involves a standard Data Science workflow: exploring data, building models, making predictions, and evaluating results. In this task, we will explore the impacts of feature selections and different sizes of training/testing data on the model performance. We will use another cleaned combined e-commerce sub-dataset that **is different from** the one in “Analysis of an E-commerce Dataset” task 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d95a739",
   "metadata": {},
   "source": [
    "### Import Cleaned E-commerce Dataset\n",
    "The csv file named 'cleaned_ecommerce_dataset.csv' is provided. You may need to use the Pandas method, i.e., `read_csv`, for reading it. After that, please print out its total length."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebff4cf",
   "metadata": {},
   "source": [
    "### Explore the Dataset\n",
    "\n",
    "* Use the methods, i.e., `head()` and `info()`, to have a rough picture about the data, e.g., how many columns, and the data types of each column.\n",
    "* As our goal is to predict ratings given other columns, please get the correlations between helpfulness/gender/category/review and rating by using the `corr()` method.\n",
    "* To get the correlations between different features, you may need to first convert the categorical features (i.e., gender, category and review) into numerial values. For doing this, you may need to import `OrdinalEncoder` from `sklearn.preprocessing` (refer to the useful exmaples [here](https://pbpython.com/categorical-encoding.html))\n",
    "* Please provide ___necessary explanations/analysis___ on the correlations, and figure out which are the ___most___ and ___least___ corrleated features regarding rating. Try to ___discuss___ how the correlation will affect the final prediction results, if we use these features to train a regression model for rating prediction. In what follows, we will conduct experiments to verify your hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1349,
   "id": "0b451dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library   \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Import ignore warnings \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1350,
   "id": "9971476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load World Development Indicators data into this notebook\n",
    "\n",
    "df = pd.read_csv(\"WorldDevelopmentIndicators.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab0daea",
   "metadata": {},
   "source": [
    "## 1. Exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1351,
   "id": "7cf9b093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the length of the dataset before cleaning\n",
    "\n",
    "print('Length of the dataset before cleaning: ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1352,
   "id": "813e289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the dataset using the method head()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1353,
   "id": "7cc29178",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Displaying the dataframe before cleaning\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1354,
   "id": "b1870f4d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Displaying a summary of the dataframe\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1355,
   "id": "eac516f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the number of countries in the dataset\n",
    "\n",
    "print('Number of countries:', len(df['Country'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1356,
   "id": "96b107ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the number of years the data has been collected across\n",
    "\n",
    "print('Number of years:', len(df['Year'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1357,
   "id": "29e6816b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the dimensions of the dataset before cleaning\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1358,
   "id": "3c97a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying descriptive statistics for Life Expectancy\n",
    "\n",
    "df['LifeExpectancy'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1359,
   "id": "d123e137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the country with the lowest life expectancy across all years\n",
    "\n",
    "LifeExpectancyMin = df['LifeExpectancy'].min()\n",
    "print(df.loc[df['LifeExpectancy'] == LifeExpectancyMin, ['Country', 'Year', 'LifeExpectancy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1360,
   "id": "31df82b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the country with the highest life expectancy across all years\n",
    "\n",
    "LifeExpectancyMax = df['LifeExpectancy'].max()\n",
    "print(df.loc[df['LifeExpectancy'] == LifeExpectancyMax, ['Country', 'Year', 'LifeExpectancy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1361,
   "id": "3c43ae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the country with the lowest life expectancy in 2020\n",
    "\n",
    "Data2020 = df.loc[df['Year'] == 2020]\n",
    "LifeExpectancyMin2020 = Data2020['LifeExpectancy'].min()\n",
    "print(df.loc[df['LifeExpectancy'] == LifeExpectancyMin2020, ['Country', 'Year', 'LifeExpectancy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1362,
   "id": "208705be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the country with the highest life expectancy in 2020\n",
    "\n",
    "Data2020 = df.loc[df['Year'] == 2020]\n",
    "LifeExpectancyMax2020 = Data2020['LifeExpectancy'].max()\n",
    "print(df.loc[df['LifeExpectancy'] == LifeExpectancyMax2020, ['Country', 'Year', 'LifeExpectancy']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928cb338",
   "metadata": {},
   "source": [
    "## 2. Cleaning the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1363,
   "id": "061dbbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the number of null values in each column\n",
    "\n",
    "print('Number of null values in Country:', df['Country'].isna().sum())\n",
    "print('Number of null values in Year:', df['Year'].isna().sum())\n",
    "print('Number of null values in Agriculture:', df['Agriculture'].isna().sum())\n",
    "print('Number of null values in Exports:', df['Exports'].isna().sum())\n",
    "print('Number of null values in FertilityRate:', df['FertilityRate'].isna().sum())\n",
    "print('Number of null values in GDP:', df['GDP'].isna().sum())\n",
    "print('Number of null values in Immunisation:', df['Immunisation'].isna().sum())\n",
    "print('Number of null values in Imports:', df['Imports'].isna().sum())\n",
    "print('Number of null values in Industry:', df['Industry'].isna().sum())\n",
    "print('Number of null values in Inflation:', df['Inflation'].isna().sum())\n",
    "print('Number of null values in MerchandiseTrade:', df['MerchandiseTrade'].isna().sum())\n",
    "print('Number of null values in MilitaryExpenditure:', df['MilitaryExpenditure'].isna().sum())\n",
    "print('Number of null values in MortalityRateU5:', df['MortalityRateU5'].isna().sum())\n",
    "print('Number of null values in NetMigration:', df['NetMigration'].isna().sum())\n",
    "print('Number of null values in DevelopmentAssistanceAndAid:', df['DevelopmentAssistanceAndAid'].isna().sum())\n",
    "print('Number of null values in PopulationDensity:', df['PopulationDensity'].isna().sum())\n",
    "print('Number of null values in PopulationGrowth:', df['PopulationGrowth'].isna().sum())\n",
    "print('Number of null values in PrimarySchoolEnrollment:', df['PrimarySchoolEnrollment'].isna().sum())\n",
    "print('Number of null values in UrbanPopulationGrowth:', df['UrbanPopulationGrowth'].isna().sum())\n",
    "print('Number of null values in LifeExpectancy:', df['LifeExpectancy'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1364,
   "id": "108e8eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing records where values are missing\n",
    "\n",
    "clean_df = df.dropna(subset=['Agriculture', \n",
    "                             'Exports', \n",
    "                             'FertilityRate', \n",
    "                             'GDP', \n",
    "                             'Immunisation', \n",
    "                             'Imports', \n",
    "                             'Industry', \n",
    "                             'Inflation', \n",
    "                             'MerchandiseTrade', \n",
    "                             'MilitaryExpenditure', \n",
    "                             'MortalityRateU5', \n",
    "                             'NetMigration', \n",
    "                             'DevelopmentAssistanceAndAid', \n",
    "                             'PopulationDensity', \n",
    "                             'PopulationGrowth', \n",
    "                             'PrimarySchoolEnrollment', \n",
    "                             'UrbanPopulationGrowth', \n",
    "                             'LifeExpectancy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1365,
   "id": "ba3a6ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the length of the dataset after cleaning\n",
    "\n",
    "print('Length of the dataset after cleaning: ', len(clean_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1366,
   "id": "8feaa99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying a summary of the cleaned dataset\n",
    "\n",
    "clean_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1424,
   "id": "d7a55db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the number of null values in each column after cleaning\n",
    "\n",
    "print('Number of null values in Country:', clean_df['Country'].isna().sum())\n",
    "print('Number of null values in Year:', clean_df['Year'].isna().sum())\n",
    "print('Number of null values in Agriculture:', clean_df['Agriculture'].isna().sum())\n",
    "print('Number of null values in Exports:', clean_df['Exports'].isna().sum())\n",
    "print('Number of null values in FertilityRate:', clean_df['FertilityRate'].isna().sum())\n",
    "print('Number of null values in GDP:', clean_df['GDP'].isna().sum())\n",
    "print('Number of null values in Immunisation:', clean_df['Immunisation'].isna().sum())\n",
    "print('Number of null values in Imports:', clean_df['Imports'].isna().sum())\n",
    "print('Number of null values in Industry:', clean_df['Industry'].isna().sum())\n",
    "print('Number of null values in Inflation:', clean_df['Inflation'].isna().sum())\n",
    "print('Number of null values in MerchandiseTrade:', clean_df['MerchandiseTrade'].isna().sum())\n",
    "print('Number of null values in MilitaryExpenditure:', clean_df['MilitaryExpenditure'].isna().sum())\n",
    "print('Number of null values in MortalityRateU5:', clean_df['MortalityRateU5'].isna().sum())\n",
    "print('Number of null values in NetMigration:', clean_df['NetMigration'].isna().sum())\n",
    "print('Number of null values in DevelopmentAssistanceAndAid:', clean_df['DevelopmentAssistanceAndAid'].isna().sum())\n",
    "print('Number of null values in PopulationDensity:', clean_df['PopulationDensity'].isna().sum())\n",
    "print('Number of null values in PopulationGrowth:', clean_df['PopulationGrowth'].isna().sum())\n",
    "print('Number of null values in PrimarySchoolEnrollment:', clean_df['PrimarySchoolEnrollment'].isna().sum())\n",
    "print('Number of null values in UrbanPopulationGrowth:', clean_df['UrbanPopulationGrowth'].isna().sum())\n",
    "print('Number of null values in LifeExpectancy:', clean_df['LifeExpectancy'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1368,
   "id": "8baaec4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the dataframe after cleaning\n",
    "\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1369,
   "id": "4ab18bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the shape of the dataset after cleaning \n",
    "\n",
    "clean_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233fa881",
   "metadata": {},
   "source": [
    "## 3. Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1370,
   "id": "602a7592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the length of the dataset after before removing outliers\n",
    "\n",
    "print('Length of the dataset before removing outliers: ', len(clean_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1371,
   "id": "f346abf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the number of records in each 5 year timespan (and prior to 1980)\n",
    "\n",
    "print('Number of records in 1960-1979:', len(clean_df[(clean_df.Year >= 1960) & (clean_df.Year < 1980)]))\n",
    "print('Number of records in 1980-1984:', len(clean_df[(clean_df.Year >= 1980) & (clean_df.Year < 1985)]))\n",
    "print('Number of records in 1985-1989:', len(clean_df[(clean_df.Year >= 1985) & (clean_df.Year < 1990)]))\n",
    "print('Number of records in 1990-1994:', len(clean_df[(clean_df.Year >= 1990) & (clean_df.Year < 1995)]))\n",
    "print('Number of records in 1995-1999:', len(clean_df[(clean_df.Year >= 1995) & (clean_df.Year < 2000)]))\n",
    "print('Number of records in 2000-2004:', len(clean_df[(clean_df.Year >= 2000) & (clean_df.Year < 2005)]))\n",
    "print('Number of records in 2005-2009:', len(clean_df[(clean_df.Year >= 2005) & (clean_df.Year < 2010)]))\n",
    "print('Number of records in 2010-2014:', len(clean_df[(clean_df.Year >= 2010) & (clean_df.Year < 2015)]))\n",
    "print('Number of records in 2015-2019:', len(clean_df[(clean_df.Year >= 2015) & (clean_df.Year < 2020)]))\n",
    "print('Number of records in 2020-2024:', len(clean_df[(clean_df.Year >= 2020) & (clean_df.Year < 2025)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1372,
   "id": "77f274bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying records collected prior to 1985\n",
    "\n",
    "before1985 = (clean_df['Year']) < 1985"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1373,
   "id": "133d7ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing records collected prior to 1985\n",
    "\n",
    "clean_df_2 = clean_df.drop(clean_df.index[before1985])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1374,
   "id": "5dd6600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the length of the dataset after removing outliers\n",
    "\n",
    "print('Length of the dataset after removing outliers: ', len(clean_df_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1375,
   "id": "750fd2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the cleaned dataset as a new file\n",
    "\n",
    "clean_df_2.to_csv('WorldDevelopmentIndicatorsClean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d81610",
   "metadata": {},
   "source": [
    "# 4. Exploring cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1376,
   "id": "8b2acbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"WorldDevelopmentIndicatorsClean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1377,
   "id": "f540a250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the length of the dataset before cleaning\n",
    "\n",
    "print('Length of the cleaned WorldDevelopmentIndicators dataset: ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1378,
   "id": "68fa061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the dataframe of the cleaned WorldDevelopmentIndicators dataset\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1379,
   "id": "890b0708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying a summary of the dataframe\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1380,
   "id": "17f0af01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the number of countries in the dataset\n",
    "\n",
    "print('Number of countries:', len(df['Country'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1381,
   "id": "711ffb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the number of years the data has been collected across\n",
    "\n",
    "print('Number of years:', len(df['Year'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1382,
   "id": "495f7cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the number of records for each country\n",
    "\n",
    "df.groupby(['Country'])['LifeExpectancy'].count().reset_index(name='Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1383,
   "id": "750e8643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the number of records for each country in ascending order\n",
    "\n",
    "(df.groupby(['Country'])['LifeExpectancy'].count().reset_index(name='Count')).sort_values(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1384,
   "id": "b6b1be71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying descriptive statistics for Life Expectancy\n",
    "\n",
    "df['LifeExpectancy'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac5a903",
   "metadata": {},
   "source": [
    "## 5. Plotting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1385,
   "id": "389ab292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the average value for each Indicator each year to be graphed\n",
    "\n",
    "byIndicator = df.groupby(['Year'])['Agriculture', \n",
    "            'Exports', \n",
    "            'FertilityRate', \n",
    "            'GDP', \n",
    "            'Immunisation', \n",
    "            'Imports', \n",
    "            'Industry', \n",
    "            'Inflation', \n",
    "            'MerchandiseTrade', \n",
    "            'MilitaryExpenditure', \n",
    "            'MortalityRateU5', \n",
    "            'NetMigration', \n",
    "            'DevelopmentAssistanceAndAid', \n",
    "            'PopulationDensity', \n",
    "            'PopulationGrowth', \n",
    "            'PrimarySchoolEnrollment', \n",
    "            'UrbanPopulationGrowth', \n",
    "            'LifeExpectancy'].mean()\n",
    "byIndicator.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1386,
   "id": "89c5e7a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting the average trends of each Indicator over time\n",
    "\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "\n",
    "byIndicator.plot.line(subplots = True, figsize = (15, 30),sharex = True)\n",
    "plt.style.use('classic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1387,
   "id": "e1b4a592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the average Life Expectancy for each Year each year to be graphed\n",
    "\n",
    "byYear = df.groupby(['Year'])['LifeExpectancy'].mean().reset_index(name='MeanLifeExpectancy')\n",
    "byYear.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1388,
   "id": "7003849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphing life expectancy against year\n",
    "\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "\n",
    "byYear.plot.line(x = 'Year', \n",
    "                 y = 'MeanLifeExpectancy', \n",
    "                 title = 'Line Graph of Life Expectancy against Year', \n",
    "                 color = 'indigo')\n",
    "plt.style.use('classic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1389,
   "id": "9d17a27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing sns package\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1390,
   "id": "e58cb693",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Graphing Life expectancy and year by country\n",
    "\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(20,30)})\n",
    "sns.scatterplot(data = df, \n",
    "                x = \"Year\", \n",
    "                y = \"LifeExpectancy\", \n",
    "                hue = \"Country\"\n",
    "               #size=\"size\", sizes=(20, 200), hue_norm=(0, 7), legend=\"full\"\n",
    "               )\n",
    "plt.style.use('classic')\n",
    "plt.title('Scatterplot of Life Expectancy by Year with Country')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f9cacd",
   "metadata": {},
   "source": [
    "## 6. Exploring the correlation of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1391,
   "id": "a970dcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the head of the dataset\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1392,
   "id": "5cc355d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing ordinal encoder\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1393,
   "id": "407c1b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring ordinal encoder - datatype is integer\n",
    "\n",
    "enc = OrdinalEncoder(dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1394,
   "id": "1741ef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 'Country' to numerical data - creating column 'CountryCode'\n",
    "\n",
    "df['CountryCode'] = enc.fit_transform(df[['Country']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1395,
   "id": "3e53ceb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the head of the dataset\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1396,
   "id": "c5c4e2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying 'Country' with new code column 'CountryCode'\n",
    "\n",
    "df[[\"Country\", \"CountryCode\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1397,
   "id": "6f653d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing records collected prior to 1985\n",
    "\n",
    "df = df.drop(columns = ['Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1398,
   "id": "b3dccf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the head of the dataset\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1399,
   "id": "c46fcc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the correlations between all indicators\n",
    "\n",
    "df[['Year',\n",
    "    'CountryCode',\n",
    "    'Agriculture', \n",
    "    'Exports', \n",
    "    'FertilityRate', \n",
    "    'GDP', \n",
    "    'Immunisation', \n",
    "    'Imports', \n",
    "    'Industry', \n",
    "    'Inflation', \n",
    "    'MerchandiseTrade', \n",
    "    'MilitaryExpenditure', \n",
    "    'MortalityRateU5', \n",
    "    'NetMigration', \n",
    "    'DevelopmentAssistanceAndAid', \n",
    "    'PopulationDensity', \n",
    "    'PopulationGrowth', \n",
    "    'PrimarySchoolEnrollment', \n",
    "    'UrbanPopulationGrowth',\n",
    "    'LifeExpectancy']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1400,
   "id": "3d18f374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the correlation between all Indicators and Life expectancy\n",
    "\n",
    "print('correlation between Year and LifeExpectancy:', df['Year'].corr(df['LifeExpectancy']))\n",
    "print('correlation between CountryCode and LifeExpectancy:', df['CountryCode'].corr(df['LifeExpectancy']))\n",
    "print('correlation between Agriculture and LifeExpectancy:', df['Agriculture'].corr(df['LifeExpectancy']))\n",
    "print('correlation between Exports and LifeExpectancyy:', df['Exports'].corr(df['LifeExpectancy']))\n",
    "print('correlation between FertilityRate and LifeExpectancy:', df['FertilityRate'].corr(df['LifeExpectancy']))\n",
    "print('correlation between GDP and LifeExpectancy:', df['GDP'].corr(df['LifeExpectancy']))\n",
    "print('correlation between Immunisation and LifeExpectancy:', df['Immunisation'].corr(df['LifeExpectancy']))\n",
    "print('correlation between Imports and LifeExpectancy:', df['Imports'].corr(df['LifeExpectancy']))\n",
    "print('correlation between Industry and LifeExpectancy:', df['Industry'].corr(df['LifeExpectancy']))\n",
    "print('correlation between Inflation and LifeExpectancy:', df['Inflation'].corr(df['LifeExpectancy']))\n",
    "print('correlation between MerchandiseTrade and LifeExpectancy:', df['MerchandiseTrade'].corr(df['LifeExpectancy']))\n",
    "print('correlation between MortalityRateU5 and LifeExpectancy:', df['MortalityRateU5'].corr(df['LifeExpectancy']))\n",
    "print('correlation between NetMigration and LifeExpectancy:', df['NetMigration'].corr(df['LifeExpectancy']))\n",
    "print('correlation between DevelopmentAssistanceAndAid and LifeExpectancy:', df['DevelopmentAssistanceAndAid'].corr(df['LifeExpectancy']))\n",
    "print('correlation between PopulationDensity and LifeExpectancy:', df['PopulationDensity'].corr(df['LifeExpectancy']))\n",
    "print('correlation between PopulationGrowth and LifeExpectancy:', df['PopulationGrowth'].corr(df['LifeExpectancy']))\n",
    "print('correlation between PrimarySchoolEnrollment and LifeExpectancy:', df['PrimarySchoolEnrollment'].corr(df['LifeExpectancy']))\n",
    "print('correlation between UrbanPopulationGrowth and LifeExpectancy:', df['UrbanPopulationGrowth'].corr(df['LifeExpectancy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1401,
   "id": "656e8943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using heatmap to show correlations\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(data= df.corr(), annot=True, cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1402,
   "id": "59c2ddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining X and Y\n",
    "X = df.drop(['LifeExpectancy'], axis = 1)\n",
    "y = df['LifeExpectancy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1403,
   "id": "a9a4ce51",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Correlation with independent variable\n",
    "\n",
    "X.corrwith(df.LifeExpectancy).plot.bar(figsize = (15, 10), title = \"Correlation with LifeExpectancy\", fontsize = 10,grid = True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1404,
   "id": "4d26e669",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Custom correlation matrix\n",
    "\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# Using df.corr() to set up the correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "# Covering the upper diagonal of the matrix\n",
    "mask = np.zeros_like(corr, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Setting up the figure\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(500, 40, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e001b5",
   "metadata": {},
   "source": [
    "## 7. Training logistic regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1405,
   "id": "5c1ca95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing Life expectancy to a categorical value so a logistic regression model can be built\n",
    "\n",
    "df1 = df\n",
    "df1['LifeExpectancy'] = df1['LifeExpectancy'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1406,
   "id": "0c93a05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1407,
   "id": "ccd254cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing train test split package\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1408,
   "id": "42ad8b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset - testing size of 20% - randomstate = 42\n",
    "\n",
    "train, test = train_test_split(df1, test_size = 0.2, random_state = 42)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1409,
   "id": "3ff9196f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Getting input data and targets for building prediction model\n",
    "\n",
    "X_train = train.drop(['LifeExpectancy'], axis=1)\n",
    "y_train = train['LifeExpectancy']\n",
    "X_test = test.drop(['LifeExpectancy'], axis=1)\n",
    "y_test = test['LifeExpectancy']\n",
    "\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1410,
   "id": "2a5508d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Logistic Regression Model\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1411,
   "id": "6dd7ee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Logistic Regression model\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1412,
   "id": "bee41f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing predictions on train and test set\n",
    "\n",
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1413,
   "id": "eb64bef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing accuracy score and confusion matrix packages\n",
    "\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix, ConfusionMatrixDisplay, accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1414,
   "id": "be779b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performance of trained model\n",
    "\n",
    "print(\"Accuracy score on training set: \", accuracy_score(y_train, y_pred_train))\n",
    "print(\"Accuracy score on testing set: \", accuracy_score(y_test, y_pred_test))\n",
    "\n",
    "# possibly discuss overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1415,
   "id": "77cfadf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying K-folds validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "accuracies = cross_val_score(estimator= clf, X=X_train, y=y_train, cv=10)\n",
    "accuracies.mean()\n",
    "accuracies.std()\n",
    "print('Logistic Regression Accuracy: %0.3f (+/- %0.3f)' % (accuracies.mean(), accuracies.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1416,
   "id": "7f217dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recursive feature elimination\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1417,
   "id": "cfd05444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE for logistic regression\n",
    "\n",
    "# Select best feature \n",
    "rfe = (RFE(clf, n_features_to_select= None)).fit(X_train, y_train)\n",
    "\n",
    "#Summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "\n",
    "print(rfe.ranking_)\n",
    "\n",
    "X_train.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1418,
   "id": "ada44bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom correlation matrix\n",
    "\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# Using df.corr() to set up the correlation matrix\n",
    "corr = X_train[X_train.columns[rfe.support_]].corr()\n",
    "\n",
    "# Covering the upper diagonal of the matrix\n",
    "mask = np.zeros_like(corr, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Setting up the figure\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(500, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1419,
   "id": "68081690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Model to the Training Set\n",
    "classifier = LogisticRegression(random_state=0)\n",
    "classifier.fit(X_train[X_train.columns[rfe.support_]], y_train)\n",
    "\n",
    "# Predicting Test Set\n",
    "y_pred_test_2 = classifier.predict(X_test[X_train.columns[rfe.support_]])\n",
    "accuracy_score(y_test, y_pred_test_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09753753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e51d815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f77a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666b1901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e953801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking confusion matrix\n",
    "\n",
    "print(\"Confusion matrix on test set: \")\n",
    "print(confusion_matrix(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1421,
   "id": "354c9490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting Test set\n",
    "y_pred = clf.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score, f1_score,recall_score,precision_score, confusion_matrix\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "prec = precision_score(y_test, y_pred, average = None)\n",
    "rec = recall_score(y_test, y_pred, average = None)\n",
    "f1 = f1_score(y_test,y_pred, average = None)\n",
    "results = pd.DataFrame([['Logistic Regression (Lasso)', acc,prec,rec,f1]],columns=['Model', 'Accuracy', 'Precision', 'Recall','F1 Score'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1422,
   "id": "3a0278ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred_test) # rows = truth, cols = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1423,
   "id": "c2222d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_test) # rows = truth, cols = prediction\n",
    "df_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(df_cm, annot=True, fmt='g')\n",
    "print(\"Test Data Accuracy: %0.4f\" % accuracy_score(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c2b79f",
   "metadata": {},
   "source": [
    "## 8. Using RFE to improve logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802a7344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating RFE object\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "rfe = RFE(estimator=lr_model, n_features_to_select=5, step=1)\n",
    "rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1969936d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19698e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Logistic Regression Model to predict 'Life expectancy' bsed on other features\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
